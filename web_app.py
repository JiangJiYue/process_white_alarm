import os
import sys
import json
import yaml
import shutil
import logging
from datetime import datetime
from pathlib import Path
from functools import wraps
from threading import Thread
from logging import LoggerAdapter

from flask import Flask, request, jsonify, render_template, send_file, redirect, url_for, flash
from werkzeug.utils import secure_filename
import pandas as pd

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

# å¯¼å…¥ç°æœ‰æ¨¡å—
from ollama_client import OllamaClient, create_ollama_client_from_config
from process_white_alarm import process_row, is_valid_path

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open('config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    with open('config.yaml', 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)

def load_tasks():
    """åŠ è½½ä»»åŠ¡æ•°æ®"""
    try:
        with open('tasks.json', 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if content:
                return json.loads(content)
            else:
                return {}
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError:
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›ç©ºå­—å…¸
        return {}

def save_tasks(tasks):
    """ä¿å­˜ä»»åŠ¡æ•°æ®"""
    with open('tasks.json', 'w', encoding='utf-8') as f:
        json.dump(tasks, f, ensure_ascii=False, indent=2)

def cleanup_tasks_on_startup():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶æ¸…ç†ä»»åŠ¡ï¼Œåªä¿ç•™å·²å®Œæˆçš„ä»»åŠ¡"""
    try:
        tasks = load_tasks()
        cleaned_tasks = {}
        removed_count = 0
        
        for task_id, task in tasks.items():
            # åªä¿ç•™çŠ¶æ€ä¸º"completed"çš„ä»»åŠ¡
            if task.get('status') == 'completed':
                cleaned_tasks[task_id] = task
            else:
                removed_count += 1
        
        # å¦‚æœæœ‰ä»»åŠ¡è¢«ç§»é™¤ï¼Œåˆ™ä¿å­˜æ¸…ç†åçš„ä»»åŠ¡åˆ—è¡¨
        if removed_count > 0:
            save_tasks(cleaned_tasks)
            print(f"æ¸…ç†äº† {removed_count} ä¸ªæœªå®Œæˆçš„ä»»åŠ¡ï¼Œåªä¿ç•™å·²å®Œæˆçš„ä»»åŠ¡")
        
        return cleaned_tasks
    except Exception as e:
        print(f"æ¸…ç†ä»»åŠ¡æ—¶å‡ºé”™: {e}")
        return load_tasks()

app = Flask(__name__)
app.secret_key = 'your_secret_key_here'

# é…ç½®
CONFIG_FILE = 'config.yaml'

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
def initialize_app():
    config = load_config()
    UPLOAD_FOLDER = config.get('web', {}).get('upload_folder', 'uploads')
    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
    return config

app_config = initialize_app()
UPLOAD_FOLDER = app_config.get('web', {}).get('upload_folder', 'uploads')
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# åœ¨åº”ç”¨å¯åŠ¨æ—¶æ¸…ç†ä»»åŠ¡
tasks = cleanup_tasks_on_startup()

# ä»»åŠ¡å­˜å‚¨ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ•°æ®åº“ï¼‰

# å­˜å‚¨ä»»åŠ¡è¿›åº¦ä¿¡æ¯
task_progress = {}

def update_task_progress(task_id, processed_rows, total_rows, status):
    """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
    task_progress[task_id] = {
        'processed_rows': processed_rows,
        'total_rows': total_rows,
        'status': status,
        'updated_at': datetime.now().isoformat()
    }

def get_task_progress(task_id):
    """è·å–ä»»åŠ¡è¿›åº¦"""
    return task_progress.get(task_id, {
        'processed_rows': 0,
        'total_rows': 0,
        'status': 'unknown',
        'updated_at': datetime.now().isoformat()
    })

def allowed_file(filename):
    config = load_config()
    allowed_extensions = config.get('web', {}).get('allowed_extensions', ['xlsx', 'xls'])
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in allowed_extensions


@app.route('/')
def index():
    """ä¸»é¡µ"""
    config = load_config()
    return render_template('index.html', config=config)

@app.route('/config', methods=['GET', 'POST'])
def config_page():
    """é…ç½®ç®¡ç†é¡µé¢"""
    if request.method == 'POST':
        try:
            # æ›´æ–°é…ç½®
            config = load_config()
            
            # æ›´æ–°Ollamaé…ç½®
            config['ollama']['url'] = request.form.get('ollama_url', config['ollama']['url'])
            config['ollama']['model_name'] = request.form.get('ollama_model_name', config['ollama']['model_name'])
            config['ollama']['timeout_seconds'] = int(request.form.get('ollama_timeout', config['ollama']['timeout_seconds']))
            config['ollama']['max_retries'] = int(request.form.get('ollama_max_retries', config['ollama']['max_retries']))
            
            # æ›´æ–°Webåº”ç”¨é…ç½®
            if 'web' not in config:
                config['web'] = {}
            config['web']['upload_folder'] = request.form.get('upload_folder', config['web'].get('upload_folder', 'uploads'))
            allowed_extensions_str = request.form.get('allowed_extensions', '')
            if allowed_extensions_str:
                config['web']['allowed_extensions'] = [ext.strip() for ext in allowed_extensions_str.split(',')]
            
            # æ›´æ–°å¤„ç†é…ç½®
            config['processing']['max_workers'] = int(request.form.get('max_workers', config['processing']['max_workers']))
            max_rows = request.form.get('max_rows_to_process', '')
            config['processing']['max_rows_to_process'] = int(max_rows) if max_rows else None
            
            # æ›´æ–°å¿½ç•¥çš„åˆ—é…ç½®
            ignored_columns_str = request.form.get('ignored_columns', '')
            if ignored_columns_str:
                config['processing']['ignored_columns'] = [col.strip() for col in ignored_columns_str.split(',') if col.strip()]
            else:
                config['processing']['ignored_columns'] = []
            
            # æ›´æ–°æ—¥å¿—é…ç½®
            config['logging']['level'] = request.form.get('log_level', config['logging']['level'])
            config['logging']['format'] = request.form.get('log_format', config['logging']['format'])
            
            # æ›´æ–°è¾“å‡ºé…ç½®
            config['output_dir'] = request.form.get('output_dir', config.get('output_dir', 'results'))
            
            # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
            config['system_prompt'] = request.form.get('system_prompt', config.get('system_prompt', ''))
            
            save_config(config)
            flash('é…ç½®å·²æ›´æ–°', 'success')
        except Exception as e:
            flash(f'é…ç½®æ›´æ–°å¤±è´¥: {str(e)}', 'error')
    
    config = load_config()
    return render_template('config.html', config=config)


@app.route('/upload', methods=['GET', 'POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼ é¡µé¢"""
    if request.method == 'POST':
        if 'file' not in request.files:
            flash('æ²¡æœ‰é€‰æ‹©æ–‡ä»¶', 'error')
            return redirect(request.url)
        
        file = request.files['file']
        if file.filename == '':
            flash('æ²¡æœ‰é€‰æ‹©æ–‡ä»¶', 'error')
            return redirect(request.url)
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            # ä¿å­˜ä»»åŠ¡ä¿¡æ¯
            task_id = f"task_{int(datetime.now().timestamp())}"
            # å…ˆåŠ è½½ç°æœ‰çš„ä»»åŠ¡
            tasks = load_tasks()
            tasks[task_id] = {
                'id': task_id,
                'filename': filename,
                'filepath': filepath,
                'status': 'uploaded',
                'created_at': datetime.now().isoformat(),
                'output_dir': None
            }
            
            # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶
            save_tasks(tasks)
            
            flash(f'æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œä»»åŠ¡ID: {task_id}', 'success')
            return redirect(url_for('task_detail', task_id=task_id))
        else:
            flash('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ Excelæ–‡ä»¶(.xlsx, .xls)', 'error')
    
    # GET è¯·æ±‚æ—¶ï¼ŒåŠ è½½å¹¶æ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨
    tasks = load_tasks()
    return render_template('upload.html', tasks=tasks)

@app.route('/preview/<task_id>')
def preview_file(task_id):
    """é¢„è§ˆä¸Šä¼ çš„æ–‡ä»¶"""
    tasks = load_tasks()
    if task_id not in tasks:
        flash('ä»»åŠ¡ä¸å­˜åœ¨', 'error')
        return redirect(url_for('upload_file'))
    
    task = tasks[task_id]
    filepath = task['filepath']
    
    try:
        # è¯»å–å‰10è¡Œæ•°æ®
        if filepath.endswith('.xlsx'):
            df = pd.read_excel(filepath)
        else:
            df = pd.read_excel(filepath, engine='xlrd')
        
        # åªå–å‰10è¡Œ
        preview_df = df.head(10)
        columns = preview_df.columns.tolist()
        rows = preview_df.values.tolist()
        
        return render_template('preview.html', task=task, columns=columns, rows=rows)
    except Exception as e:
        flash(f'æ–‡ä»¶é¢„è§ˆå¤±è´¥: {str(e)}', 'error')
        return redirect(url_for('upload_file'))

@app.route('/task/<task_id>')
def task_detail(task_id):
    """ä»»åŠ¡è¯¦æƒ…é¡µé¢"""
    tasks = load_tasks()
    if task_id not in tasks:
        flash('ä»»åŠ¡ä¸å­˜åœ¨', 'error')
        return redirect(url_for('upload_file'))
    
    task = tasks[task_id]
    return render_template('task_detail.html', task=task)

def process_task_async(task_id, max_rows_override=None):
    """å¼‚æ­¥å¤„ç†ä»»åŠ¡"""
    tasks = load_tasks()
    if task_id not in tasks:
        return
    
    task = tasks[task_id]
    try:
        # åŠ è½½é…ç½®
        config = load_config()
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¾“å‡ºç›®å½•ï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
        output_base_dir = config.get('output_dir', 'results')
        # åˆ›å»ºåŸºäºæ—¶é—´æˆ³çš„å”¯ä¸€è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = os.path.join(output_base_dir, f"run_{timestamp}")
        os.makedirs(output_dir, exist_ok=True)
        task['output_dir'] = output_dir
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task['status'] = 'processing'
        task['started_at'] = datetime.now().isoformat()
        update_task_progress(task_id, 0, 0, 'processing')
        
        # ä¿å­˜ä»»åŠ¡çŠ¶æ€
        save_tasks(tasks)
        
        # å¤åˆ¶è¾“å…¥æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
        input_filepath = os.path.join(output_dir, task['filename'])
        shutil.copy2(task['filepath'], input_filepath)
        
        # å¤„ç†æ–‡ä»¶
        df = pd.read_excel(task['filepath'])
        total_rows = len(df)
        task['total_rows'] = total_rows
        update_task_progress(task_id, 0, total_rows, 'processing')
        
        # åº”ç”¨å‚æ•°è¦†ç›–ï¼ˆå¦‚æœæœ‰ï¼‰
        if max_rows_override:
            max_rows_override = int(max_rows_override)
            df = df.head(max_rows_override)
            task['processed_rows'] = len(df)
        else:
            # æ£€æŸ¥é…ç½®ä¸­çš„é»˜è®¤è®¾ç½®
            default_max_rows = config.get('processing', {}).get('max_rows_to_process')
            if default_max_rows is not None:
                df = df.head(default_max_rows)
                task['processed_rows'] = len(df)
            else:
                task['processed_rows'] = total_rows
        
        # åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
        ollama_client = create_ollama_client_from_config(config)
        
        # è®¾ç½®æ—¥å¿—æ–‡ä»¶
        log_dir = config.get('logging', {}).get('log_dir', 'logs')
        os.makedirs(log_dir, exist_ok=True)
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ—¥å¿—æ–‡ä»¶æ¨¡æ¿
        log_file_template = config["logging"].get("log_file", "{log_dir}/{task_id}_{timestamp}.log")
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # æ›¿æ¢å ä½ç¬¦ç”Ÿæˆæ—¥å¿—æ–‡ä»¶è·¯å¾„
        log_filename = log_file_template.replace("{log_dir}", log_dir).replace("{timestamp}", timestamp).replace("{task_id}", task_id)
        log_filepath = os.path.join(log_dir, os.path.basename(log_filename))  # ç¡®ä¿æ–‡ä»¶åœ¨log_dirç›®å½•ä¸‹
        
        # é…ç½®æ—¥å¿—æ ¼å¼
        LOG_LEVEL = getattr(logging, config["logging"]["level"].upper())
        LOG_FORMAT = config["logging"].get("format", "text")  # é»˜è®¤ä¸ºæ–‡æœ¬æ ¼å¼
        
        if LOG_FORMAT == "json":
            # JSONæ ¼å¼æ—¥å¿—
            class JsonFormatter(logging.Formatter):
                def format(self, record):
                    log_entry = {
                        "timestamp": self.formatTime(record),
                        "level": record.levelname,
                        "message": record.getMessage()
                    }
                    if hasattr(record, 'task_id'):
                        log_entry["task_id"] = record.task_id
                    return json.dumps(log_entry, ensure_ascii=False)
            
            formatter = JsonFormatter()
        else:
            # æ–‡æœ¬æ ¼å¼æ—¥å¿—
            class TextFormatter(logging.Formatter):
                def format(self, record):
                    log_message = super().format(record)
                    if hasattr(record, 'task_id'):
                        log_message = f"[task_{record.task_id}] {log_message}"
                    return log_message
            
            # ä½¿ç”¨ä¸process_white_alarm.pyç›¸åŒçš„æ ¼å¼
            formatter = TextFormatter("%(asctime)s [%(levelname)s] %(message)s")
        
        # ä¸ºå½“å‰ä»»åŠ¡åˆ›å»ºä¸“ç”¨çš„æ—¥å¿—è®°å½•å™¨
        task_logger = logging.getLogger(f"task_{task_id}")
        task_logger.setLevel(LOG_LEVEL)
        
        # ç§»é™¤ç°æœ‰çš„å¤„ç†å™¨
        for handler in task_logger.handlers[:]:
            task_logger.removeHandler(handler)
            handler.close()
        
        # æ·»åŠ æ–°çš„å¤„ç†å™¨
        # ä½¿ç”¨ RotatingFileHandler å®ç°æ—¥å¿—è½®è½¬
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            log_filepath, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=20,
            encoding='utf-8'
        )
        file_handler.setFormatter(formatter)
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        
        task_logger.addHandler(file_handler)
        task_logger.addHandler(console_handler)
        
        # ç«‹å³å†™å…¥ä¸€æ¡æ—¥å¿—ï¼Œç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©º
        task_logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id}")
        
        # åˆ›å»ºä»»åŠ¡æ—¥å¿—é€‚é…å™¨å·¥å‚ï¼Œç”¨äºä¼ é€’ç»™ process_white_alarm æ¨¡å—
        def task_logger_factory(task_id):
            return LoggerAdapter(task_logger, {'task_id': task_id})
        
        # å°†ä»»åŠ¡æ—¥å¿—è®°å½•å™¨ä¼ é€’ç»™ process_row å‡½æ•°
        import process_white_alarm
        process_white_alarm.set_task_logger_factory(task_logger_factory)
        
        # å¤„ç†è¿‡ç¨‹
        valid_results = []
        invalid_records = []
        
        for idx, row in df.iterrows():
            try:
                result = process_row(row, idx)
                if result["type"] == "no_path_found":
                    invalid_records.append({
                        "åºå·": idx + 1,
                        "åŸå§‹è·¯å¾„": "<åŸå§‹è¡Œæœªæå–åˆ°ä»»ä½•è·¯å¾„>",
                        "æ–‡ä»¶å": "<æ— æ–‡ä»¶å>",
                        "ç±»å‹": "æœªçŸ¥",
                        "åº”ç”¨åç§°": "<æ— >",
                        "è¾“å…¥å†…å®¹": str(result["row"])
                    })
                elif result["type"] == "processed":
                    for output in result["outputs"]:
                        raw_path = output["åŸå§‹è·¯å¾„"]
                        is_valid = is_valid_path(raw_path, allow_filename_only=True)
                        task_logger.debug(f"è·¯å¾„éªŒè¯ç»“æœ: {repr(raw_path)} -> {'æœ‰æ•ˆ' if is_valid else 'æ— æ•ˆ'}")
                        if is_valid:
                            valid_results.append(output)
                            task_logger.debug(f"æ·»åŠ æœ‰æ•ˆç»“æœ: {repr(raw_path)}")
                        else:
                            invalid_records.append(output)
                            task_logger.debug(f"æ·»åŠ æ— æ•ˆè®°å½•: {repr(raw_path)}")
                
                # æ›´æ–°è¿›åº¦
                update_task_progress(task_id, idx + 1, total_rows, 'processing')
            except Exception as e:
                task_logger.error(f"å¤„ç†è¡Œ {idx} æ—¶å‡ºé”™: {e}", exc_info=True)
                invalid_records.append({
                    "åºå·": idx + 1,
                    "åŸå§‹è·¯å¾„": f"<å¤„ç†å‡ºé”™: {str(e)}>",
                    "æ–‡ä»¶å": "<æ— æ–‡ä»¶å>",
                    "ç±»å‹": "é”™è¯¯",
                    "åº”ç”¨åç§°": "<æ— >",
                    "è¾“å…¥å†…å®¹": str(row.to_dict())
                })
        
        # ä¿å­˜ç»“æœ
        if invalid_records:
            invalid_df = pd.DataFrame(invalid_records)
            cols = ["åºå·", "åŸå§‹è·¯å¾„", "æ–‡ä»¶å", "ç±»å‹", "åº”ç”¨åç§°", "è¾“å…¥å†…å®¹"]
            for col in cols:
                if col not in invalid_df.columns:
                    invalid_df[col] = ""
            invalid_df = invalid_df[cols]
            invalid_df.to_excel(os.path.join(output_dir, "invalid_records.xlsx"), index=False)
        
        if valid_results:
            result_df = pd.DataFrame(valid_results)
            result_df.sort_values("åºå·", inplace=True, ignore_index=True)
            result_df.to_excel(os.path.join(output_dir, "valid_results.xlsx"), index=False)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task['status'] = 'completed'
        task['completed_at'] = datetime.now().isoformat()
        task['valid_count'] = len(valid_results)
        task['invalid_count'] = len(invalid_records)
        update_task_progress(task_id, total_rows, total_rows, 'completed')
        
        # è®°å½•ä»»åŠ¡å®Œæˆæ—¥å¿—
        task_logger.info(f"ä»»åŠ¡ {task_id} å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆç»“æœ: {len(valid_results)}, æ— æ•ˆè®°å½•: {len(invalid_records)}")
        
        # æ·»åŠ ç±»ä¼¼äº main() å‡½æ•°ä¸­çš„æ—¥å¿—è®°å½•
        if invalid_records:
            task_logger.info(f"ğŸ’¾ å·²ä¿å­˜ {len(invalid_records)} æ¡æ— æ•ˆè®°å½•åˆ° {os.path.join(output_dir, 'invalid_records.xlsx')}")
        
        if valid_results:
            task_logger.info(f"âœ… å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {len(valid_results)} æ¡æœ‰æ•ˆè·¯å¾„ç»“æœï¼Œå·²ä¿å­˜åˆ° {os.path.join(output_dir, 'valid_results.xlsx')}")
        else:
            task_logger.warning("âš ï¸ æœªç”Ÿæˆä»»ä½•æœ‰æ•ˆè·¯å¾„ç»“æœ")
        
        task_logger.info(f"ğŸ“„ è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: {log_filepath}")
        task_logger.info(f"ğŸ“ æœ‰æ•ˆç»“æœä¿å­˜åœ¨: {os.path.join(output_dir, 'valid_results.xlsx')}")
        task_logger.info(f"ğŸ“ æ— æ•ˆè®°å½•ä¿å­˜åœ¨: {os.path.join(output_dir, 'invalid_records.xlsx')}")
        
        # ä¿å­˜ä»»åŠ¡çŠ¶æ€
        tasks = load_tasks()  # é‡æ–°åŠ è½½ä»»åŠ¡ä»¥é˜²åœ¨å¤„ç†è¿‡ç¨‹ä¸­æœ‰æ›´æ–°
        if task_id in tasks:
            tasks[task_id].update(task)
            save_tasks(tasks)
        
        # å…³é—­æ—¥å¿—å¤„ç†å™¨
        for handler in task_logger.handlers[:]:
            handler.close()
            task_logger.removeHandler(handler)
            
    except Exception as e:
        task['status'] = 'failed'
        task['error'] = str(e)
        update_task_progress(task_id, 0, 0, 'failed')
        logging.error(f"å¤„ç†ä»»åŠ¡ {task_id} æ—¶å‡ºé”™: {e}", exc_info=True)
        
        # ä¿å­˜ä»»åŠ¡çŠ¶æ€
        tasks = load_tasks()  # é‡æ–°åŠ è½½ä»»åŠ¡ä»¥é˜²åœ¨å¤„ç†è¿‡ç¨‹ä¸­æœ‰æ›´æ–°
        if task_id in tasks:
            tasks[task_id].update(task)
            save_tasks(tasks)

@app.route('/process/<task_id>', methods=['POST'])
def process_task(task_id):
    """å¤„ç†ä»»åŠ¡ - ç«‹å³è¿”å›ï¼Œå®é™…å¤„ç†åœ¨åå°è¿›è¡Œ"""
    # åŠ è½½æœ€æ–°çš„ä»»åŠ¡æ•°æ®
    tasks = load_tasks()
    if task_id not in tasks:
        return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    
    # è·å–è¡¨å•å‚æ•°
    max_rows_override = request.form.get('max_rows_override')
    
    # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡å¤„ç†
    thread = Thread(target=process_task_async, args=(task_id, max_rows_override))
    thread.start()
    
    # ç«‹å³è¿”å›æˆåŠŸå“åº”
    return jsonify({'status': 'success', 'message': 'ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨åå°å¤„ç†ä¸­'})

@app.route('/tasks')
def task_list():
    """ä»»åŠ¡åˆ—è¡¨"""
    tasks = load_tasks()
    return render_template('task_list.html', tasks=tasks)

@app.route('/task/delete/<task_id>', methods=['POST'])
def delete_task(task_id):
    """åˆ é™¤ä»»åŠ¡åŠå…¶ç›¸å…³æ–‡ä»¶"""
    tasks = load_tasks()
    if task_id not in tasks:
        flash('ä»»åŠ¡ä¸å­˜åœ¨', 'error')
        return redirect(url_for('task_list'))
    
    task = tasks[task_id]
    
    try:
        # åˆ é™¤è¾“å‡ºç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if task.get('output_dir') and os.path.exists(task['output_dir']):
            shutil.rmtree(task['output_dir'])
        
        # åˆ é™¤æ—¥å¿—æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        config = load_config()
        log_dir = config.get('logging', {}).get('log_dir', 'logs')
        
        # æŸ¥æ‰¾å¹¶åˆ é™¤åŒ¹é…çš„ä»»åŠ¡æ—¥å¿—æ–‡ä»¶ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§å‘½åè§„èŒƒï¼‰
        if os.path.exists(log_dir):
            for filename in os.listdir(log_dir):
                if (filename.startswith(f"{task_id}_") or filename.startswith(f"task_{task_id}_")) and filename.endswith(".log"):
                    log_filepath = os.path.join(log_dir, filename)
                    if os.path.exists(log_filepath):
                        os.remove(log_filepath)
        
        # ä»ä»»åŠ¡å­—å…¸ä¸­åˆ é™¤ä»»åŠ¡
        del tasks[task_id]
        
        # ä¿å­˜æ›´æ–°åçš„ä»»åŠ¡åˆ—è¡¨
        save_tasks(tasks)
        
        flash(f'ä»»åŠ¡ {task_id} å·²æˆåŠŸåˆ é™¤', 'success')
    except Exception as e:
        logging.error(f"åˆ é™¤ä»»åŠ¡ {task_id} æ—¶å‡ºé”™: {e}", exc_info=True)
        flash(f'åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}', 'error')
    
    return redirect(url_for('task_list'))

@app.route('/download/<task_id>/<file_type>')
def download_file(task_id, file_type):
    """ä¸‹è½½ç»“æœæ–‡ä»¶"""
    tasks = load_tasks()
    if task_id not in tasks:
        flash('ä»»åŠ¡ä¸å­˜åœ¨', 'error')
        return redirect(url_for('task_list'))
    
    task = tasks[task_id]
    if not task.get('output_dir'):
        flash('ä»»åŠ¡å°šæœªå®Œæˆ', 'error')
        return redirect(url_for('task_detail', task_id=task_id))
    
    file_map = {
        'valid': 'valid_results.xlsx',
        'invalid': 'invalid_records.xlsx'
    }
    
    if file_type not in file_map:
        flash('æ–‡ä»¶ç±»å‹ä¸æ”¯æŒ', 'error')
        return redirect(url_for('task_detail', task_id=task_id))
    
    file_path = os.path.join(task['output_dir'], file_map[file_type])
    if not os.path.exists(file_path):
        flash('æ–‡ä»¶ä¸å­˜åœ¨', 'error')
        return redirect(url_for('task_detail', task_id=task_id))
    
    return send_file(file_path, as_attachment=True)

@app.route('/api/config', methods=['GET', 'POST'])
def api_config():
    """é…ç½®ç®¡ç†API"""
    if request.method == 'GET':
        return jsonify(load_config())
    elif request.method == 'POST':
        try:
            config = request.get_json()
            save_config(config)
            return jsonify({'status': 'success', 'message': 'é…ç½®å·²æ›´æ–°'})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 400

@app.route('/api/process', methods=['POST'])
def api_process():
    """å¤„ç†ä»»åŠ¡API"""
    try:
        data = request.get_json()
        filepath = data.get('filepath')
        if not filepath or not os.path.exists(filepath):
            return jsonify({'status': 'error', 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 400
        
        # åˆ›å»ºä»»åŠ¡
        task_id = f"api_task_{int(datetime.now().timestamp())}"
        filename = os.path.basename(filepath)
        tasks[task_id] = {
            'id': task_id,
            'filename': filename,
            'filepath': filepath,
            'status': 'processing',
            'created_at': datetime.now().isoformat(),
            'output_dir': None
        }
        
        # è¿™é‡Œåº”è¯¥å®é™…å¤„ç†ä»»åŠ¡ï¼Œä½†ä¸ºäº†ç®€åŒ–ç¤ºä¾‹ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿå¤„ç†
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„å¤„ç†é€»è¾‘
        tasks[task_id]['status'] = 'completed'
        tasks[task_id]['completed_at'] = datetime.now().isoformat()
        tasks[task_id]['valid_count'] = 0
        tasks[task_id]['invalid_count'] = 0
        
        return jsonify({
            'status': 'success',
            'task_id': task_id,
            'message': 'ä»»åŠ¡å¤„ç†å®Œæˆ'
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tasks')
def api_tasks():
    """ä»»åŠ¡åˆ—è¡¨API"""
    return jsonify(list(tasks.values()))

@app.route('/api/task/<task_id>')
def api_task_detail(task_id):
    """ä»»åŠ¡è¯¦æƒ…API"""
    if task_id not in tasks:
        return jsonify({'status': 'error', 'message': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    return jsonify(tasks[task_id])

@app.route('/api/task/<task_id>/progress')
def api_task_progress(task_id):
    """è·å–ä»»åŠ¡è¿›åº¦API"""
    if task_id not in tasks:
        return jsonify({'status': 'error', 'message': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    
    progress = get_task_progress(task_id)
    task = tasks[task_id]
    
    return jsonify({
        'status': 'success',
        'data': {
            'task_id': task_id,
            'task_status': task['status'],
            'progress': progress
        }
    })

@app.route('/api/logs/<task_id>')
def get_task_log(task_id):
    """è·å–ä»»åŠ¡æ—¥å¿—"""
    tasks = load_tasks()
    if task_id not in tasks:
        return jsonify({'status': 'error', 'message': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    
    task = tasks[task_id]
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
    if '..' in task_id or '/' in task_id or '\\' in task_id:
        return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„ä»»åŠ¡ID'}), 400
    
    # ä»é…ç½®ä¸­è·å–æ—¥å¿—ç›®å½•
    config = load_config()
    log_dir = config.get('logging', {}).get('log_dir', 'logs')
    
    # æŸ¥æ‰¾åŒ¹é…çš„ä»»åŠ¡æ—¥å¿—æ–‡ä»¶ï¼ˆä½¿ç”¨æ–°çš„å‘½åè§„èŒƒï¼‰
    log_filename = None
    if os.path.exists(log_dir):
        for filename in os.listdir(log_dir):
            if filename.startswith(f"{task_id}_") and filename.endswith(".log"):
                log_filename = filename
                break
    
    # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šæ ¼å¼çš„æ—¥å¿—æ–‡ä»¶ï¼Œå°è¯•æŸ¥æ‰¾æ—§æ ¼å¼çš„æ—¥å¿—æ–‡ä»¶
    if log_filename is None:
        log_filename = f"task_{task_id}.log"
    
    log_filepath = os.path.join(log_dir, log_filename)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(log_filepath):
        return jsonify({'status': 'error', 'message': 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    
    try:
        # è¯»å–æ—¥å¿—æ–‡ä»¶å†…å®¹ï¼ˆä»¥åªè¯»æ¨¡å¼æ‰“å¼€ï¼Œæ”¯æŒæ­£åœ¨è¢«å†™å…¥çš„æ–‡ä»¶ï¼‰
        with open(log_filepath, 'r', encoding='utf-8') as f:
            log_content = f.read()
        return jsonify({'status': 'success', 'data': log_content})
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    app.run(debug=True)