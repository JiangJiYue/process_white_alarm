from pathlib import Path

import pandas as pd
import re
import logging
import os
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import yaml
from logging import LoggerAdapter
from datetime import datetime
import contextvars

# å¯¼å…¥æŠ½ç¦»çš„ Ollama æ¨¡å—
from ollama_client import OllamaClient, create_ollama_client_from_config, test_ollama_connection

# ================== ä»é…ç½®æ–‡ä»¶åŠ è½½ ==================
with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

# è·å–è¾“å‡ºç›®å½•é…ç½®ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
OUTPUT_DIR = config.get("output_dir", "output/run_{}".format(datetime.now().strftime("%Y%m%d_%H%M%S")))

# åœ¨è¾“å‡ºç›®å½•ä¸­å®šä¹‰è¾“å‡ºæ–‡ä»¶
INVALID_OUTPUT_FILE = os.path.join(OUTPUT_DIR, "invalid_records.xlsx")
RESULT_OUTPUT_FILE = os.path.join(OUTPUT_DIR, "valid_results.xlsx")

# æ—¥å¿—æ–‡ä»¶é…ç½®
LOG_DIR = config["logging"].get("log_dir", "logs")
LOG_FILE_TEMPLATE = config["logging"]["log_file"]

# åˆ›å»ºæ—¥å¿—ç›®å½•
os.makedirs(LOG_DIR, exist_ok=True)

# æ›¿æ¢å ä½ç¬¦ç”Ÿæˆæ—¥å¿—æ–‡ä»¶è·¯å¾„
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# æ³¨æ„ï¼šstandaloneæ¨¡å¼å·²è¢«å¼ƒç”¨ï¼Œä¸ä¼šå†ç”Ÿæˆstandalone_*.logæ–‡ä»¶
# æ‰€æœ‰æ—¥å¿—ç°åœ¨éƒ½åœ¨Webåº”ç”¨ä¸­é€šè¿‡ä»»åŠ¡IDè¿›è¡Œç®¡ç†

OLLAMA_CONFIG = config["ollama"]

MAX_WORKERS = config["processing"]["max_workers"]
MAX_ROWS_TO_PROCESS = config["processing"]["max_rows_to_process"]  # å¯ä¸º null â†’ None

LOG_LEVEL = getattr(logging, config["logging"]["level"].upper())
LOG_FORMAT = config["logging"].get("format", "text")  # é»˜è®¤ä¸ºæ–‡æœ¬æ ¼å¼

SYSTEM_PROMPT = config["system_prompt"].rstrip()

# ===================================================

# ================== æ—¥å¿—é…ç½® ==================
# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ç§»é™¤æ—§çš„æ ¹æ—¥å¿—è®°å½•å™¨é…ç½®ï¼Œé¿å…ç”Ÿæˆstandaloneæ—¥å¿—æ–‡ä»¶
# æ‰€æœ‰æ—¥å¿—ç°åœ¨éƒ½åœ¨Webåº”ç”¨ä¸­é€šè¿‡ä»»åŠ¡IDè¿›è¡Œç®¡ç†
logger = logging.getLogger(__name__)

# ä»»åŠ¡æ—¥å¿—å·¥å‚
def task_logger_factory(row_number):
    # è®¾ç½®ä¸Šä¸‹æ–‡å˜é‡
    row_context_var.set(row_number)
    return LoggerAdapter(logger, {'row_number': row_number})

# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨ä»»åŠ¡æ—¥å¿—è®°å½•å™¨å·¥å‚å‡½æ•°
_task_logger_factory = None
_logger = None

def set_task_logger_factory(factory):
    """è®¾ç½®ä»»åŠ¡æ—¥å¿—è®°å½•å™¨å·¥å‚å‡½æ•°"""
    global _task_logger_factory
    _task_logger_factory = factory

def set_logger(logger):
    """è®¾ç½®å…¨å±€æ—¥å¿—è®°å½•å™¨"""
    global _logger
    _logger = logger

def get_task_logger(row_number):
    """è·å–ä»»åŠ¡æ—¥å¿—è®°å½•å™¨"""
    if _task_logger_factory:
        return _task_logger_factory(row_number)
    else:
        # å¦‚æœæ²¡æœ‰è®¾ç½®å·¥å‚å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªç©ºçš„æ—¥å¿—è®°å½•å™¨
        return logging.getLogger("dummy")

# åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯ï¼Œä¼ é€’logger
# ollama_client = create_ollama_client_from_config(config)

# å»¶è¿Ÿåˆå§‹åŒ– Ollama å®¢æˆ·ç«¯ï¼Œä½¿ç”¨ä¼ é€’çš„æ—¥å¿—è®°å½•å™¨
def get_ollama_client():
    global ollama_client
    if 'ollama_client' not in globals() or ollama_client is None:
        if _logger:
            ollama_client = create_ollama_client_from_config(config, logger=_logger)
        else:
            ollama_client = create_ollama_client_from_config(config)
    return ollama_client

# ä¿®æ”¹ call_ollama_model å‡½æ•°ä»¥ä½¿ç”¨å»¶è¿Ÿåˆå§‹åŒ–çš„ Ollama å®¢æˆ·ç«¯
def call_ollama_model(input_text, row_number):
    task_logger = get_task_logger(row_number)
    task_logger.debug({"event": "ollama_input", "input": input_text})

    # ä½¿ç”¨å»¶è¿Ÿåˆå§‹åŒ–çš„ Ollama å®¢æˆ·ç«¯
    client = get_ollama_client()
    success, result_text, metadata = client.call_model(
        prompt=input_text,
        system_prompt=SYSTEM_PROMPT,
        temperature=0.0,
        num_predict=500,
        task_id=f"task_{row_number}"  # ä¸ºäº†å…¼å®¹æ—§æ¥å£
    )

    if not success:
        error_msg = metadata.get('error', 'Unknown error')
        task_logger.warning({"event": "ollama_call_failed", "error": error_msg})
        return [{
            "åºå·": row_number,
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": clean_excel_string(f"<è°ƒç”¨å¤±è´¥: {error_msg}>"),
            "æ–‡ä»¶å": clean_excel_string("<æ— æ–‡ä»¶å>"),
            "ç±»å‹": "æœªçŸ¥",
            "åº”ç”¨åç§°": clean_excel_string("<æ— >")
        }]

    # --- ğŸ”§ æ–°å¢ï¼šå¢å¼º JSON æ¸…æ´—é€»è¾‘ ---
    cleaned_text = result_text.strip()
    
    # è®°å½•åŸå§‹å“åº”å’Œæ¸…æ´—å‰çš„æ–‡æœ¬
    task_logger.debug({"event": "raw_model_response", "response": result_text})
    
    # 1. ç§»é™¤å¼€å¤´çš„ "json" æˆ– "```json" ç­‰æ ‡è®°
    cleaned_text = re.sub(r'^```json\s*', '', cleaned_text)
    cleaned_text = re.sub(r'^```\s*json\s*', '', cleaned_text)
    cleaned_text = re.sub(r'^json\s*', '', cleaned_text, flags=re.IGNORECASE)
    
    # 2. ç§»é™¤ç»“å°¾çš„ "```"
    cleaned_text = re.sub(r'\s*```$', '', cleaned_text)
    
    # 3. æ‰¾åˆ° JSON å¼€å§‹ä½ç½®ï¼ˆç¬¬ä¸€ä¸ª '{' æˆ– '['ï¼‰
    start_brace = cleaned_text.find('{')
    start_bracket = cleaned_text.find('[')
    start_pos = min(start_brace if start_brace != -1 else float('inf'), start_bracket if start_bracket != -1 else float('inf'))
    if start_pos != float('inf'):
        cleaned_text = cleaned_text[int(start_pos):]
    else:
        # å¦‚æœæ‰¾ä¸åˆ°å¼€å§‹ç¬¦å·ï¼Œå°è¯•ä»ç¬¬ä¸€ä¸ªå­—æ¯å¼€å§‹æ‰¾å¯¹è±¡æˆ–æ•°ç»„
        cleaned_text = cleaned_text.lstrip()
    
    # 4. å°è¯•ä»åå¾€å‰æ‰¾åˆ°ç»“æŸç¬¦å·ï¼Œç¡®ä¿ JSON å®Œæ•´
    # ï¼ˆé˜²æ­¢ Ollama æˆªæ–­å“åº”ï¼‰
    last_brace = cleaned_text.rfind('}')
    last_bracket = cleaned_text.rfind(']')
    end_pos = max(last_brace, last_bracket)
    if end_pos != -1:
        cleaned_text = cleaned_text[:end_pos + 1]
    
    cleaned_text = cleaned_text.strip()
    
    # è®°å½•æ¸…æ´—åçš„æ–‡æœ¬
    task_logger.debug({"event": "cleaned_model_response", "response": cleaned_text})
    
    # --- END JSON æ¸…æ´— ---

    try:
        data = json.loads(cleaned_text)
    except json.JSONDecodeError as e:
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè®°å½•æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        task_logger.warning({
            "event": "json_parse_failed",
            "error": str(e),
            "cleaned_response": repr(cleaned_text),
            "original_response_snippet": result_text[:500]  # è®°å½•æ›´å¤šä¸Šä¸‹æ–‡
        })
        return [{
            "åºå·": row_number,
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": clean_excel_string(f"<JSONè§£æå¤±è´¥: {str(e)[:100]}>"),
            "æ–‡ä»¶å": clean_excel_string("<æ— æ–‡ä»¶å>"),
            "ç±»å‹": "æœªçŸ¥",
            "åº”ç”¨åç§°": clean_excel_string("<æ— >")
        }]

    final_outputs = []
    if isinstance(data, list):
        for i, item in enumerate(data, 1):  # ä»1å¼€å§‹ç¼–å·
            if isinstance(item, dict):
                path = clean_excel_string(item.get("path", "<æ— è·¯å¾„>"))
                filename = clean_excel_string(item.get("filename", "<æ— æ–‡ä»¶å>"))
                typ = clean_excel_string(item.get("type", "æœªçŸ¥"))
                app = clean_excel_string(item.get("app", "<æ— >"))
                
                # è®°å½•æ¯ä¸ªæå–çš„è·¯å¾„ä¿¡æ¯ï¼Œä½¿ç”¨ollamaNæ ¼å¼
                # task_logger.debug({
                #     "event": "extracted_path", 
                #     "path": path, 
                #     "filename": filename, 
                #     "type": typ, 
                #     "app": app,
                #     "ollama_id": f"ollama{i}"
                # })
                
                final_outputs.append({
                    "åºå·": row_number,
                    "è¾“å…¥å†…å®¹": input_text,
                    "åŸå§‹è·¯å¾„": path,
                    "æ–‡ä»¶å": filename,
                    "ç±»å‹": typ,
                    "åº”ç”¨åç§°": app
                })
    elif isinstance(data, dict):
        path = clean_excel_string(data.get("path", "<æ— è·¯å¾„>"))
        filename = clean_excel_string(data.get("filename", "<æ— æ–‡ä»¶å>"))
        typ = clean_excel_string(data.get("type", "æœªçŸ¥"))
        app = clean_excel_string(data.get("app", "<æ— >"))
        
        # è®°å½•æå–çš„è·¯å¾„ä¿¡æ¯ï¼Œä½¿ç”¨ollama1æ ¼å¼ï¼ˆå•ä¸ªç»“æœï¼‰
        # task_logger.debug({
        #     "event": "extracted_path", 
        #     "path": path, 
        #     "filename": filename, 
        #     "type": typ, 
        #     "app": app,
        #     "ollama_id": "ollama1"
        # })
        
        final_outputs.append({
            "åºå·": row_number,
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": path,
            "æ–‡ä»¶å": filename,
            "ç±»å‹": typ,
            "åº”ç”¨åç§°": app
        })

    # task_logger.debug({"event": "ollama_processed", "count": len(final_outputs)})
    return final_outputs


def parse_filter_conditions(filter_str):
    """
    è§£æè¿‡æ»¤æ¡ä»¶å­—ç¬¦ä¸²ä¸­çš„é”®å€¼å¯¹
    ä¾‹å¦‚: 'æ•°æ®æº = "EDR" and å‘½ä»¤è¡Œ = "powershell -enc ..."' 
    è¿”å›: {'æ•°æ®æº': 'EDR', 'å‘½ä»¤è¡Œ': 'powershell -enc ...'}
    """
    if not isinstance(filter_str, str):
        return {}
    
    # å…ˆæŒ‰ "and" åˆ†å‰²å„ä¸ªæ¡ä»¶
    conditions = re.split(r'\s+and\s+', filter_str)
    
    result = {}
    # ä¸ºæ¯ä¸ªæ¡ä»¶åŒ¹é…é”®å€¼å¯¹
    for condition in conditions:
        pattern = r'([^=]+?)\s*=\s*("[^"]*"|\'[^\']*\'|\S+)'
        match = re.match(pattern, condition)
        if match:
            key, value = match.groups()
            # æ¸…ç†é”®å’Œå€¼
            clean_key = key.strip()
            clean_value = value.strip().strip('"\'')
            result[clean_key] = clean_value
    
    return result

def process_row(row, idx, selected_columns=None, ignored_columns=None):
    original_index = idx + 1
    row_dict = row.to_dict()

    # è·å–ä»»åŠ¡ç‰¹å®šçš„æ—¥å¿—è®°å½•å™¨
    task_logger = get_task_logger(original_index)

    input_text = ""

    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†é€‰æ‹©çš„åˆ—ï¼Œåˆ™ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„åˆ—
    if selected_columns is not None and len(selected_columns) > 0:
        parts = []
        # åªä½¿ç”¨ç”¨æˆ·é€‰å®šçš„åˆ—
        for col in selected_columns:
            val = row_dict.get(col)
            if pd.notna(val) and str(val).strip():
                # æ£€æŸ¥æ˜¯å¦æ•´ä¸ªåˆ—è¢«å¿½ç•¥
                if col in ignored_columns:
                    task_logger.debug(f"[task_{original_index}] åˆ— '{col}' è¢«ç”¨æˆ·å¿½ç•¥ï¼Œè·³è¿‡å¤„ç†")
                    continue
                # å¤„ç†æ‰€æœ‰åˆ—
                # å¦‚æœæœ‰éœ€è¦å¿½ç•¥çš„é”®å€¼å¯¹ï¼Œå°è¯•è§£æå¹¶è¿‡æ»¤
                filtered_val = str(val).strip()
                if ignored_columns:
                    # å°è¯•è§£æå½“å‰åˆ—æ˜¯å¦ä¸ºé”®å€¼å¯¹æ ¼å¼ï¼Œå¦‚æœæ˜¯åˆ™è¿‡æ»¤
                    filtered_val = filter_ignored_keys_from_filter_condition(str(val).strip(), ignored_columns)
                
                # å¦‚æœè¿‡æ»¤åè¿˜æœ‰å†…å®¹åˆ™æ·»åŠ 
                if filtered_val:
                    parts.append(filtered_val)
                    # task_logger.debug(f"æ·»åŠ åˆ— '{col}' çš„å†…å®¹: {repr(filtered_val)}")
                else:
                    task_logger.debug(f"åˆ— '{col}' è¿‡æ»¤åæ— å†…å®¹ï¼Œè·³è¿‡æ·»åŠ ")
        
        input_text = " ; ".join(parts)
        task_logger.debug(f"æœ€ç»ˆæ‹¼æ¥çš„è¾“å…¥æ–‡æœ¬: {repr(input_text)}")
    else:
        # å¦‚æœç”¨æˆ·æ²¡æœ‰åœ¨é¡µé¢ä¸Šé€‰æ‹©ç‰¹å®šçš„åˆ—ï¼Œåˆ™è¿”å›é”™è¯¯æç¤ºï¼Œè¦æ±‚ç”¨æˆ·è‡³å°‘é€‰æ‹©ä¸€åˆ—
        task_logger.debug(f"ç”¨æˆ·æœªé€‰æ‹©ä»»ä½•åˆ—ï¼Œæ— æ³•å¤„ç†")
        return {
            "type": "no_path_found",
            "row": row_dict,
            "error": "ç”¨æˆ·æœªé€‰æ‹©ä»»ä½•åˆ—ï¼Œè¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—è¿›è¡Œå¤„ç†"
        }
        
    # ç›´æ¥å°†æ¸…ç†åçš„å†…å®¹äº¤ç»™ Ollama
    desc = "è¯·ä»ä»¥ä¸‹å®‰å…¨å‘Šè­¦å†…å®¹ä¸­æå–æ‰€æœ‰ç¨‹åºè·¯å¾„ã€æ–‡ä»¶åï¼Œå¹¶åˆ†ç±»è¾“å‡ºï¼š\n" + input_text
    # task_logger.debug(f"å‘é€è¯·æ±‚åˆ° Ollama: {repr(desc)}")
    parsed_results = call_ollama_model(desc, original_index)
    
    task_logger.debug(f"Ollama å¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœæ•°: {len(parsed_results)}")

    return {"type": "processed", "outputs": parsed_results}


def is_valid_path(value, allow_filename_only=True):
    """
    ä½¿ç”¨Pythonå†…ç½®å‡½æ•°åˆ¤æ–­æ˜¯å¦ä¸ºåˆæ³•è·¯å¾„
    """
    if not isinstance(value, str):
        return False
    # æ‹’ç» URL
    if value.lower().startswith(('http://', 'https://', 'ftp://', 'file://', 'mailto:', 'javascript:')):
        return False
    # æ‹’ç»ç‰¹æ®Šæ ‡è®°
    if value.startswith('<') and value.endswith('>'):
        return False
    try:
        # ä½¿ç”¨Pathlibæ¥éªŒè¯è·¯å¾„
        path = Path(value)

        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«éæ³•å­—ç¬¦ï¼ˆWindowsç‰¹å®šï¼‰
        if os.name == 'nt':  # Windowsç³»ç»Ÿ
            illegal_chars = '<>:"|?*'
            if any(char in value for char in illegal_chars):
                return False

        # å¦‚æœå…è®¸æ–‡ä»¶åä¸”ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
        if allow_filename_only and not path.is_absolute():
            is_valid = len(value) <= 255
            # è®°å½•éªŒè¯ç»“æœ
            if not is_valid:
                logger.debug(f"è·¯å¾„éªŒè¯å¤±è´¥ï¼ˆæ–‡ä»¶åå¤ªé•¿ï¼‰: {repr(value)}")
            return is_valid

        # å¯¹äºç»å¯¹è·¯å¾„ï¼Œæ£€æŸ¥åŸºæœ¬æ ¼å¼
        if path.is_absolute():
            return True

        # å°è¯•è§„èŒƒåŒ–è·¯å¾„ï¼Œçœ‹æ˜¯å¦æœ‰æ•ˆ
        normalized = path.resolve()
        is_valid = str(normalized) != '/'
        # è®°å½•éªŒè¯ç»“æœ
        if not is_valid:
            logger.debug(f"è·¯å¾„éªŒè¯å¤±è´¥ï¼ˆè§„èŒƒåŒ–åæ— æ•ˆï¼‰: {repr(value)}")
        return is_valid

    except Exception as e:
        logger.debug(f"è·¯å¾„éªŒè¯å¼‚å¸¸: {repr(value)}, é”™è¯¯: {e}")
        return False


def clean_filter_string(filter_str):
    """
    æ¸…ç†è¿‡æ»¤æ¡ä»¶å­—ç¬¦ä¸²ï¼Œç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦
    """
    return filter_str.strip()


def clean_excel_string(value):
    """
    æ¸…ç†å­—ç¬¦ä¸²ï¼Œä½¿å…¶é€‚åˆå†™å…¥Excel
    """
    if isinstance(value, str):
        return value.replace("\n", " ").replace("\r", " ").replace("\t", " ")
    return value


def filter_ignored_keys_from_filter_condition(filter_str, ignored_columns):
    """
    ä»è¿‡æ»¤æ¡ä»¶å­—ç¬¦ä¸²ä¸­ç§»é™¤è¢«å¿½ç•¥çš„é”®å€¼å¯¹
    
    Args:
        filter_str (str): åŸå§‹è¿‡æ»¤æ¡ä»¶å­—ç¬¦ä¸²
        ignored_columns (list): è¦å¿½ç•¥çš„åˆ—ååˆ—è¡¨
        
    Returns:
        str: è¿‡æ»¤åçš„å­—ç¬¦ä¸²ï¼Œå¦‚æœå…¨éƒ¨è¢«è¿‡æ»¤åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not isinstance(filter_str, str) or not ignored_columns:
        return filter_str
    
    # å…ˆæŒ‰ "and" åˆ†å‰²å„ä¸ªæ¡ä»¶
    conditions = re.split(r'\s+and\s+', filter_str)
    
    # å­˜å‚¨æœªè¢«å¿½ç•¥çš„æ¡ä»¶
    remaining_conditions = []
    
    # æ£€æŸ¥æ¯ä¸ªæ¡ä»¶
    for condition in conditions:
        # åŒ¹é… "key = value" æ ¼å¼
        pattern = r'^([^=]+?)\s*=\s*("[^"]*"|\'[^\']*\'|\S+)'
        match = re.match(pattern, condition.strip())
        if match:
            key = match.group(1).strip()
            # å¦‚æœé”®ä¸åœ¨å¿½ç•¥åˆ—è¡¨ä¸­ï¼Œåˆ™ä¿ç•™è¯¥æ¡ä»¶
            if key not in ignored_columns:
                remaining_conditions.append(condition)
        else:
            # å¦‚æœä¸åŒ¹é…key=valueæ ¼å¼ï¼Œä¿ç•™åŸæ ·
            remaining_conditions.append(condition)
    
    # é‡æ–°ç»„åˆæ¡ä»¶
    return " and ".join(remaining_conditions) if remaining_conditions else ""
