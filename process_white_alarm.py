import sys
from pathlib import Path

import pandas as pd
import re
import logging
import os
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import yaml
from logging import LoggerAdapter
from datetime import datetime

# å¯¼å…¥æŠ½ç¦»çš„ Ollama æ¨¡å—
from ollama_client import OllamaClient, create_ollama_client_from_config, test_ollama_connection

# ================== ä»é…ç½®æ–‡ä»¶åŠ è½½ ==================
with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

# è·å–è¾“å‡ºç›®å½•é…ç½®ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
OUTPUT_DIR = config.get("output_dir", "output/run_{}".format(datetime.now().strftime("%Y%m%d_%H%M%S")))

# åœ¨è¾“å‡ºç›®å½•ä¸­å®šä¹‰è¾“å‡ºæ–‡ä»¶
INVALID_OUTPUT_FILE = os.path.join(OUTPUT_DIR, "invalid_records.xlsx")
RESULT_OUTPUT_FILE = os.path.join(OUTPUT_DIR, "valid_results.xlsx")

# æ—¥å¿—æ–‡ä»¶é…ç½®
LOG_DIR = config["logging"].get("log_dir", "logs")
LOG_FILE_TEMPLATE = config["logging"]["log_file"]

# åˆ›å»ºæ—¥å¿—ç›®å½•
os.makedirs(LOG_DIR, exist_ok=True)

# æ›¿æ¢å ä½ç¬¦ç”Ÿæˆæ—¥å¿—æ–‡ä»¶è·¯å¾„
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
LOG_FILE = LOG_FILE_TEMPLATE.replace("{log_dir}", LOG_DIR).replace("{timestamp}", timestamp)

OLLAMA_CONFIG = config["ollama"]

MAX_WORKERS = config["processing"]["max_workers"]
MAX_ROWS_TO_PROCESS = config["processing"]["max_rows_to_process"]  # å¯ä¸º null â†’ None

LOG_LEVEL = getattr(logging, config["logging"]["level"].upper())
LOG_FORMAT = config["logging"].get("format", "text")  # é»˜è®¤ä¸ºæ–‡æœ¬æ ¼å¼

SYSTEM_PROMPT = config["system_prompt"].rstrip()

# ===================================================

# ================== æ—¥å¿—é…ç½® ==================
# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)

# é…ç½®æ—¥å¿—æ ¼å¼
if LOG_FORMAT == "json":
    # JSONæ ¼å¼æ—¥å¿—
    class JsonFormatter(logging.Formatter):
        def format(self, record):
            log_entry = {
                "timestamp": self.formatTime(record),
                "level": record.levelname,
                "message": record.getMessage()
            }
            if hasattr(record, 'task_id'):
                log_entry["task_id"] = record.task_id
            return json.dumps(log_entry, ensure_ascii=False)
    
    formatter = JsonFormatter()
else:
    # æ–‡æœ¬æ ¼å¼æ—¥å¿—
    class TextFormatter(logging.Formatter):
        def format(self, record):
            log_message = super().format(record)
            if hasattr(record, 'task_id'):
                log_message = f"[task_{record.task_id}] {log_message}"
            return log_message
    
    formatter = TextFormatter("%(asctime)s [%(levelname)s] %(message)s")

# é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
root_logger = logging.getLogger()
root_logger.setLevel(LOG_LEVEL)

# ç§»é™¤ç°æœ‰çš„å¤„ç†å™¨
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)
    handler.close()

# æ·»åŠ æ–°çš„å¤„ç†å™¨
file_handler = logging.FileHandler(LOG_FILE, encoding='utf-8')
file_handler.setFormatter(formatter)
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)

root_logger.addHandler(file_handler)
root_logger.addHandler(console_handler)

logger = logging.getLogger(__name__)

# ä»»åŠ¡æ—¥å¿—å·¥å‚
def task_logger_factory(task_id):
    return LoggerAdapter(logger, {'task_id': task_id})

# åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯ï¼Œä¼ é€’logger
ollama_client = create_ollama_client_from_config(config)


def clean_excel_string(s):
    """
    å½»åº•æ¸…æ´—å­—ç¬¦ä¸²ï¼Œç§»é™¤æ‰€æœ‰ Excel ä¸æ”¯æŒçš„æ§åˆ¶å­—ç¬¦å’Œå¸¸è§éšè—å­—ç¬¦ã€‚
    """
    if not isinstance(s, str):
        s = str(s)
    # ç§»é™¤ ASCII æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™ \t \n \rï¼‰
    s = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', s)
    # ç§»é™¤ Unicode éšè—/æ ¼å¼å­—ç¬¦ï¼ˆé›¶å®½ç©ºæ ¼ã€BOMã€åŒå‘æ§åˆ¶ç¬¦ç­‰ï¼‰
    s = re.sub(r'[\u200B-\u200D\uFEFF\u202A-\u202E\u00AD\u180E]', '', s)
    return s.strip()


def is_valid_path(value, allow_filename_only=True):
    """
    ä½¿ç”¨Pythonå†…ç½®å‡½æ•°åˆ¤æ–­æ˜¯å¦ä¸ºåˆæ³•è·¯å¾„
    """
    if not isinstance(value, str):
        return False
    # æ‹’ç» URL
    if value.lower().startswith(('http://', 'https://', 'ftp://', 'file://', 'mailto:', 'javascript:')):
        return False
    # æ‹’ç»ç‰¹æ®Šæ ‡è®°
    if value.startswith('<') and value.endswith('>'):
        return False
    try:
        # ä½¿ç”¨Pathlibæ¥éªŒè¯è·¯å¾„
        path = Path(value)

        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«éæ³•å­—ç¬¦ï¼ˆWindowsç‰¹å®šï¼‰
        if os.name == 'nt':  # Windowsç³»ç»Ÿ
            illegal_chars = '<>:"|?*'
            if any(char in value for char in illegal_chars):
                return False

        # å¦‚æœå…è®¸æ–‡ä»¶åä¸”ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
        if allow_filename_only and not path.is_absolute():
            return len(value) <= 255

        # å¯¹äºç»å¯¹è·¯å¾„ï¼Œæ£€æŸ¥åŸºæœ¬æ ¼å¼
        if path.is_absolute():
            return True

        # å°è¯•è§„èŒƒåŒ–è·¯å¾„ï¼Œçœ‹æ˜¯å¦æœ‰æ•ˆ
        normalized = path.resolve()
        return str(normalized) != '/'

    except Exception:
        return False


def clean_filter_string(filter_str):
    """
    æ¸…ç†è¿‡æ»¤æ¡ä»¶å­—ç¬¦ä¸²ï¼š
      - ç§»é™¤ 'ç»„ç»‡æœºæ„ = "..."'
      - ç§»é™¤ 'æ•°æ®æº = "..."'
    è¿”å›æ¸…ç†åçš„å­—ç¬¦ä¸²ï¼ˆä¿ç•™å…¶ä»–æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬ rlikeï¼‰
    """
    if not isinstance(filter_str, str):
        return filter_str

    cleaned = re.sub(r'\s*ç»„ç»‡æœºæ„\s*=\s*"[^"]*"', '', filter_str)
    cleaned = re.sub(r'\s*æ•°æ®æº\s*=\s*"[^"]*"', '', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned


def call_ollama_model(input_text, task_id):
    task_logger = task_logger_factory(task_id)
    task_logger.debug({"event": "ollama_input", "input": input_text})

    success, result_text, metadata = ollama_client.call_model(
        prompt=input_text,
        system_prompt=SYSTEM_PROMPT,
        temperature=0.0,
        num_predict=500,
        task_id=task_id
    )

    if not success:
        error_msg = metadata.get('error', 'Unknown error')
        task_logger.warning({"event": "ollama_call_failed", "error": error_msg})
        return [{
            "åºå·": int(task_id.split('_')[1]),
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": clean_excel_string(f"<è°ƒç”¨å¤±è´¥: {error_msg}>"),
            "æ–‡ä»¶å": clean_excel_string("<æ— æ–‡ä»¶å>"),
            "ç±»å‹": "æœªçŸ¥",
            "åº”ç”¨åç§°": clean_excel_string("<æ— >")
        }]

    # --- ğŸ”§ æ–°å¢ï¼šå¢å¼º JSON æ¸…æ´—é€»è¾‘ ---
    cleaned_text = result_text.strip()

    # 1. ç§»é™¤å¼€å¤´çš„ "json" æˆ– "```json" ç­‰æ ‡è®°
    cleaned_text = re.sub(r'^```json\s*', '', cleaned_text)
    cleaned_text = re.sub(r'^```\s*json\s*', '', cleaned_text)
    cleaned_text = re.sub(r'^json\s*', '', cleaned_text, flags=re.IGNORECASE)

    # 2. ç§»é™¤ç»“å°¾çš„ "```"
    cleaned_text = re.sub(r'\s*```$', '', cleaned_text)

    # 3. æ‰¾åˆ° JSON å¼€å§‹ä½ç½®ï¼ˆç¬¬ä¸€ä¸ª '{' æˆ– '['ï¼‰
    start_brace = cleaned_text.find('{')
    start_bracket = cleaned_text.find('[')
    start_pos = min(start_brace if start_brace != -1 else float('inf'), start_bracket if start_bracket != -1 else float('inf'))
    if start_pos != float('inf'):
        cleaned_text = cleaned_text[int(start_pos):]
    else:
        # å¦‚æœæ‰¾ä¸åˆ°å¼€å§‹ç¬¦å·ï¼Œå°è¯•ä»ç¬¬ä¸€ä¸ªå­—æ¯å¼€å§‹æ‰¾å¯¹è±¡æˆ–æ•°ç»„
        cleaned_text = cleaned_text.lstrip()

    # 4. å°è¯•ä»åå¾€å‰æ‰¾åˆ°ç»“æŸç¬¦å·ï¼Œç¡®ä¿ JSON å®Œæ•´
    # ï¼ˆé˜²æ­¢ Ollama æˆªæ–­å“åº”ï¼‰
    last_brace = cleaned_text.rfind('}')
    last_bracket = cleaned_text.rfind(']')
    end_pos = max(last_brace, last_bracket)
    if end_pos != -1:
        cleaned_text = cleaned_text[:end_pos + 1]

    cleaned_text = cleaned_text.strip()

    # --- END JSON æ¸…æ´— ---

    try:
        data = json.loads(cleaned_text)
    except json.JSONDecodeError as e:
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè®°å½•æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        task_logger.warning({
            "event": "json_parse_failed",
            "error": str(e),
            "cleaned_response": repr(cleaned_text),
            "original_response_snippet": result_text[:500]  # è®°å½•æ›´å¤šä¸Šä¸‹æ–‡
        })
        return [{
            "åºå·": int(task_id.split('_')[1]),
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": clean_excel_string(f"<JSONè§£æå¤±è´¥: {str(e)[:100]}>"),
            "æ–‡ä»¶å": clean_excel_string("<æ— æ–‡ä»¶å>"),
            "ç±»å‹": "æœªçŸ¥",
            "åº”ç”¨åç§°": clean_excel_string("<æ— >")
        }]

    if not isinstance(data, list):
        data = [data]

    results = []
    for item in data[:10]:
        if not isinstance(item, dict):
            path, filename, typ, app = "<éå¯¹è±¡å…ƒç´ >", "<æ— æ–‡ä»¶å>", "æœªçŸ¥", "<æ— >"
        else:
            raw_path = item.get("path", "<ç¼ºå¤±path>")
            raw_filename = item.get("filename", "<æ— æ–‡ä»¶å>")
            raw_type = item.get("type", "æœªçŸ¥")
            raw_app = item.get("app", "<æ— >")
            path = clean_excel_string(str(raw_path)).strip()
            filename = clean_excel_string(str(raw_filename)).strip()
            typ = clean_excel_string(str(raw_type)).strip()
            app = clean_excel_string(str(raw_app)).strip()

        results.append({
            "åºå·": int(task_id.split('_')[1]),
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": path,
            "æ–‡ä»¶å": filename,
            "ç±»å‹": typ,
            "åº”ç”¨åç§°": app
        })

    if not results:
        results.append({
            "åºå·": int(task_id.split('_')[1]),
            "è¾“å…¥å†…å®¹": input_text,
            "åŸå§‹è·¯å¾„": clean_excel_string("<æ— æ³•ç¡®å®šè·¯å¾„>"),
            "æ–‡ä»¶å": clean_excel_string("<æ— æ–‡ä»¶å>"),
            "ç±»å‹": "æœªçŸ¥",
            "åº”ç”¨åç§°": clean_excel_string("<æ— >")
        })

    return results


def process_row(row, idx):
    original_index = idx + 1
    row_dict = row.to_dict()

    input_text = ""

    # ä¼˜å…ˆä½¿ç”¨ "è¿‡æ»¤æ¡ä»¶" åˆ—ï¼ˆå¦‚æœå­˜åœ¨ä¸”éç©ºï¼‰
    if "è¿‡æ»¤æ¡ä»¶" in row_dict and pd.notna(row_dict["è¿‡æ»¤æ¡ä»¶"]):
        raw_filter = str(row_dict["è¿‡æ»¤æ¡ä»¶"]).strip()
        if raw_filter:
            input_text = clean_filter_string(raw_filter)
            logger.debug(f"æ¸…ç†åçš„è¿‡æ»¤æ¡ä»¶ (åºå·{original_index}): {repr(input_text)}")

    # å¦‚æœæ²¡æœ‰è¿‡æ»¤æ¡ä»¶ï¼Œæˆ–æ¸…ç†åä¸ºç©ºï¼Œåˆ™æ‹¼æ¥æ•´è¡Œï¼ˆè·³è¿‡ç»„ç»‡æœºæ„å’Œæ•°æ®æºï¼‰
    if not input_text.strip():
        parts = []
        for col, val in row_dict.items():
            if col in ["ç»„ç»‡æœºæ„", "æ•°æ®æº"]:
                continue
            if pd.notna(val) and str(val).strip():
                parts.append(f"{col} = {str(val).strip()}")
        input_text = " ; ".join(parts)
        logger.debug(f"ä½¿ç”¨æ•´è¡Œæ‹¼æ¥ (åºå·{original_index}): {repr(input_text)}")

    # å¦‚æœæœ€ç»ˆ input_text ä»ä¸ºç©ºï¼Œåˆ™æ ‡è®°ä¸ºæ— è·¯å¾„
    if not input_text.strip():
        return {
            "type": "no_path_found",
            "row": row_dict
        }

    # ç›´æ¥å°†æ¸…ç†åçš„å†…å®¹äº¤ç»™ Ollama
    desc = "è¯·ä»ä»¥ä¸‹å®‰å…¨å‘Šè­¦å†…å®¹ä¸­æå–æ‰€æœ‰å¯ç–‘ç¨‹åºè·¯å¾„ã€æ–‡ä»¶åï¼Œå¹¶åˆ†ç±»è¾“å‡ºï¼š\n" + input_text
    parsed_results = call_ollama_model(desc, f"task_{original_index}")

    return {"type": "processed", "outputs": parsed_results}


# ================== ä¸»å‡½æ•° ==================
def main():
    logger.info("ğŸ§ª æµ‹è¯• Ollama è¿æ¥...")
    if not test_ollama_connection(ollama_client):
        logger.error("âŒ Ollama è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return

    logger.info("ğŸš€ å¼€å§‹å¤„ç† Excel æ–‡ä»¶: %s", INPUT_FILE)

    # æ³¨æ„ï¼šæˆ‘ä»¬ä¸å†éœ€è¦åˆ é™¤æ—§æ–‡ä»¶ï¼Œå› ä¸ºæ¯æ¬¡è¿è¡Œéƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å¸¦æœ‰æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
    logger.info("ğŸ“‚ è¾“å‡ºç›®å½•: %s", OUTPUT_DIR)

    if not os.path.exists(INPUT_FILE):
        logger.error("âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: %s", INPUT_FILE)
        raise FileNotFoundError(f"æ–‡ä»¶ {INPUT_FILE} ä¸å­˜åœ¨")

    df = pd.read_excel(INPUT_FILE)
    total_rows = len(df)
    logger.info("ğŸ“Š æˆåŠŸåŠ è½½ Excelï¼Œå…± %d è¡Œ", total_rows)

    if MAX_ROWS_TO_PROCESS is not None and isinstance(MAX_ROWS_TO_PROCESS, int) and MAX_ROWS_TO_PROCESS > 0:
        df = df.head(MAX_ROWS_TO_PROCESS)
        logger.info("âœ‚ï¸ ä»…å¤„ç†å‰ %d è¡Œï¼ˆç”± MAX_ROWS_TO_PROCESS é…ç½®ï¼‰", len(df))

    invalid_records = []
    valid_results = []

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(process_row, row, idx): idx
            for idx, row in df.iterrows()
        }

        for future in as_completed(futures):
            try:
                result = future.result()
                idx_in_df = futures[future]
                original_index = idx_in_df + 1

                if result["type"] == "no_path_found":
                    invalid_records.append({
                        "åºå·": original_index,
                        "åŸå§‹è·¯å¾„": "<åŸå§‹è¡Œæœªæå–åˆ°ä»»ä½•è·¯å¾„>",
                        "æ–‡ä»¶å": "<æ— æ–‡ä»¶å>",
                        "ç±»å‹": "æœªçŸ¥",
                        "åº”ç”¨åç§°": "<æ— >",
                        "è¾“å…¥å†…å®¹": str(result["row"])
                    })
                elif result["type"] == "processed":
                    for output in result["outputs"]:
                        raw_path = output["åŸå§‹è·¯å¾„"]
                        is_valid = is_valid_path(raw_path, allow_filename_only=True)
                        logger.debug(f"è·¯å¾„éªŒè¯ç»“æœ: {repr(raw_path)} -> {is_valid}")
                        if is_valid:
                            valid_results.append(output)
                        else:
                            invalid_records.append(output)
            except Exception as e:
                logger.error(f"ğŸ”¥ å¤„ç†æŸè¡Œæ—¶å‘ç”Ÿæœªé¢„æœŸå¼‚å¸¸: {e}", exc_info=True)

    if invalid_records:
        invalid_df = pd.DataFrame(invalid_records)
        cols = ["åºå·", "åŸå§‹è·¯å¾„", "æ–‡ä»¶å", "ç±»å‹", "åº”ç”¨åç§°", "è¾“å…¥å†…å®¹"]
        for col in cols:
            if col not in invalid_df.columns:
                invalid_df[col] = ""
        invalid_df = invalid_df[cols]
        invalid_df.to_excel(INVALID_OUTPUT_FILE, index=False)
        logger.info("ğŸ’¾ å·²ä¿å­˜ %d æ¡æ— æ•ˆè®°å½•åˆ° %s", len(invalid_df), INVALID_OUTPUT_FILE)

    if valid_results:
        result_df = pd.DataFrame(valid_results)
        result_df.sort_values("åºå·", inplace=True, ignore_index=True)
        result_df.to_excel(RESULT_OUTPUT_FILE, index=False)
        logger.info("âœ… å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ %d æ¡æœ‰æ•ˆè·¯å¾„ç»“æœï¼Œå·²ä¿å­˜åˆ° %s", len(result_df), RESULT_OUTPUT_FILE)
    else:
        logger.warning("âš ï¸ æœªç”Ÿæˆä»»ä½•æœ‰æ•ˆè·¯å¾„ç»“æœ")

    logger.info("ğŸ“„ è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: %s", LOG_FILE)
    logger.info("ğŸ“ æœ‰æ•ˆç»“æœä¿å­˜åœ¨: %s", RESULT_OUTPUT_FILE)
    logger.info("ğŸ“ æ— æ•ˆè®°å½•ä¿å­˜åœ¨: %s", INVALID_OUTPUT_FILE)


if __name__ == "__main__":
    main()